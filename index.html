<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Pavan Konam | AI Engineer</title>
  <meta name="description" content="AI Engineer portfolio of Pavan Konam — projects, experience, education, and contact." />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700;800&display=swap" rel="stylesheet">
  <style>
    :root{
      --navy:#0a2342; --navy-2:#0e2d57; --accent:#7dd3fc; --text:#e6f1ff; --muted:#b8c3d9; --chip:#11355f;
      --shadow: 0 20px 40px rgba(0,0,0,.25); --radius:18px; --radius-sm:12px; --maxw:1100px;
    }
    *{box-sizing:border-box}
    html,body{margin:0;padding:0;background:var(--navy)!important;color:var(--text)!important;font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Cantarell,Noto Sans,sans-serif;line-height:1.6}
    img{max-width:100%;display:block}
    a{color:var(--accent);text-decoration:none}
    a:hover{opacity:.9}
    .wrap{width:100%;max-width:var(--maxw);margin:0 auto;padding:0 20px}
    header{position:sticky;top:0;background:rgba(10,35,66,.85);backdrop-filter:saturate(150%) blur(8px);z-index:50;border-bottom:1px solid rgba(255,255,255,.06)}
    nav{display:flex;align-items:center;justify-content:space-between;height:64px}
    .brand{display:flex;gap:12px;align-items:center}
    .logo{width:40px;height:40px;border-radius:50%;box-shadow:var(--shadow);object-fit:cover;display:block;flex:0 0 40px}
    .brand h1{margin:0;font-size:18px;letter-spacing:.4px}
    .links{display:flex;gap:18px}
    .links a{font-weight:600;opacity:.9}

    .hero{position:relative;min-height:68vh;padding:0;border-bottom:1px solid rgba(255,255,255,.06);background:#071a33;overflow:hidden}
.hero::before{content:"";position:absolute;inset:0;background:url('gallery/newyork.jpg') center/cover no-repeat;opacity:.6;filter:saturate(1) contrast(1.05)}
.hero::after{content:"";position:absolute;inset:0;background:radial-gradient(1200px 600px at 20% 10%, rgba(125,211,252,.18), transparent), linear-gradient(180deg, rgba(10,35,66,.15), rgba(10,35,66,.65))}
.hero-content{position:relative;z-index:1;display:flex;align-items:center;justify-content:center;min-height:68vh}
.hero-inner{max-width:var(--maxw);padding:0 20px}
.hero-title{font-size: clamp(36px, 7vw, 64px);line-height:1.05;margin:0 0 10px;font-weight:900;letter-spacing:.3px;opacity:0;transform:translateY(16px);animation:fadeUp .9s .1s forwards cubic-bezier(.22,1,.36,1)}
.hero-sub{font-size: clamp(16px, 2.4vw, 24px);color:var(--muted);max-width:900px;margin:0 0 18px;opacity:0;transform:translateY(12px);animation:fadeUp .9s .25s forwards cubic-bezier(.22,1,.36,1)}
.hero-cta{display:flex;gap:12px;opacity:0;transform:translateY(12px);animation:fadeUp .9s .4s forwards cubic-bezier(.22,1,.36,1)}
.name-accent{background:linear-gradient(90deg,#7dd3fc,#c4b5fd,#7dd3fc);-webkit-background-clip:text;background-clip:text;color:transparent;display:inline-block;animation: shimmer 2.5s linear infinite}
@keyframes shimmer{0%{background-position:0% 50%}100%{background-position:200% 50%}}
@keyframes fadeUp{to{opacity:1;transform:none}}
.grid-2{display:grid;grid-template-columns:1.2fr .8fr;gap:32px}
    .grid-2{display:grid;grid-template-columns:1.2fr .8fr;gap:32px}
    h2.section-title{font-size:28px;margin:0 0 8px}
    .kicker{color:var(--muted);font-weight:600;letter-spacing:.12em;text-transform:uppercase;font-size:12px}
    .title{font-size:42px;line-height:1.15;margin:.2em 0 .35em;font-weight:800}
    .subtitle{font-size:18px;color:var(--muted);max-width:700px}
    .cta{display:flex;gap:12px;margin-top:20px}
    .btn{display:inline-flex;align-items:center;gap:10px;padding:12px 16px;border-radius:14px;background:#1b3f72;color:white;font-weight:700;border:1px solid rgba(255,255,255,.08);box-shadow:var(--shadow)}
    .btn.secondary{background:transparent;border-color:rgba(255,255,255,.14);color:var(--text)}

    .card{background:var(--navy-2);border:1px solid rgba(255,255,255,.06);border-radius:var(--radius);box-shadow:var(--shadow)}
    .card-inner{padding:22px}

    .chips{display:flex;flex-wrap:wrap;gap:10px;margin-top:12px}
    .chip{background:var(--chip);color:var(--text);padding:8px 12px;border-radius:999px;font-size:12px;border:1px solid rgba(255,255,255,.07)}

    section{padding:42px 0}
    .cols{display:grid;gap:18px}
    @media(min-width:900px){.cols{grid-template-columns:1fr 1fr}}

    .entry{padding:18px;border-radius:var(--radius-sm);background:rgba(255,255,255,.03);border:1px solid rgba(255,255,255,.06)}
    .entry h3{margin:0 0 6px;font-size:18px}
    .entry .meta{font-size:12px;color:var(--muted)}

    .projects{display:grid;gap:22px}
    @media(min-width:840px){.projects{grid-template-columns:1fr 1fr}}
    .project{overflow:hidden}
    .cover{height:220px;background:#0d2a4e;border-bottom:1px solid rgba(255,255,255,.06);display:flex;align-items:center;justify-content:center}
    .cover span{color:#9ecbff;opacity:.8}

    .project .card-inner{display:flex;flex-direction:column;gap:10px}
    .tagline{color:var(--muted)}

    footer{padding:36px 0;border-top:1px solid rgba(255,255,255,.06);color:var(--muted)}
    .footer-grid{display:grid;gap:18px}
    @media(min-width:720px){.footer-grid{grid-template-columns:2fr 1fr 1fr}}

    /* smooth anchors */
    html{scroll-behavior:smooth}
  
    /* TIMELINE */
    .timeline{position:relative; padding:14px 0 6px}
    .timeline::before{content:""; position:absolute; left:50%; top:0; bottom:0; width:3px; background:linear-gradient(180deg, rgba(125,211,252,.55), rgba(255,255,255,.08)); border-radius:6px; box-shadow:0 0 0 1px rgba(255,255,255,.04) inset}
    .tl-wrap{display:grid; gap:24px}
    .tl-item{position:relative; width:calc(50% - 28px); background:rgba(255,255,255,.04); border:1px solid rgba(255,255,255,.08); border-radius:14px; box-shadow:var(--shadow); padding:16px 18px; transform:translateX(var(--off,0)) translateZ(0); transition:transform .7s cubic-bezier(.22,1,.36,1)}
    .tl-item.in{opacity:1; filter:saturate(1); --off:0}
    .tl-item h3{margin:0 0 6px;font-size:18px}
    .tl-item .meta{font-size:12px;color:var(--muted)}
    .tl-item p{margin:10px 0 0}
    .tl-item .connector{position:absolute; top:50%; width:28px; height:2px; background:rgba(125,211,252,.6); transform-origin:right center; transition:transform .5s ease, opacity .5s ease; opacity:.75}
    .tl-item.left{margin-right:auto; --off:-48px}
    .tl-item.left .connector{right:-28px; transform:scaleX(0)}
    .tl-item.right{margin-left:auto; --off:48px}
    .tl-item.right .connector{left:-28px; transform:scaleX(0); transform-origin:left center}
    .tl-item .dot{position:absolute; top:50%; left:50%; width:12px; height:12px; background:#7dd3fc; border:2px solid #0a2342; border-radius:999px; translate:-50% -50%; box-shadow:0 0 0 4px rgba(125,211,252,.18)}
    .tl-item.in .connector{transform:scaleX(1)}
    .tl-item:hover{transform:translateX(0) scale(1.01)}
    /* small screens: single column */
    @media(max-width:820px){
      .timeline::before{left:10px}
      .tl-item{width:100%; padding-left:28px}
      .tl-item.left,.tl-item.right{margin:0; --off:0}
      .tl-item .connector{left:10px; width:18px}
      .tl-item .dot{left:10px; translate:-50% -50%}
    }
  
    /* Video gallery */
    .video-grid{display:grid;gap:22px}
    @media(min-width:840px){.video-grid{grid-template-columns:1fr 1fr}}
    .vid-card{overflow:hidden;border-radius:var(--radius);background:var(--navy-2);border:1px solid rgba(255,255,255,.06);box-shadow:var(--shadow)}
    .vid-wrap{position:relative;background:#0d2a4e}
    .vid-wrap video{width:100%;height:100%;display:block}
    .vid-meta{padding:16px;color:var(--muted)}
  
    /* H-scroll projects */
    .projects-h{position:relative;display:flex;gap:22px;overflow-x:auto;padding:6px 0 14px;margin:0;scroll-snap-type:x mandatory;-webkit-overflow-scrolling:touch;scroll-behavior:smooth}
    .projects-h::-webkit-scrollbar{height:10px}
    .projects-h::-webkit-scrollbar-thumb{background:rgba(255,255,255,.15);border-radius:999px}
    /* >>> CHANGE: show two projects per view on desktop, one on mobile <<< */
    .projects-h .project{
      flex:0 0 calc(50% - 11px);
      min-width:calc(50% - 11px);
      scroll-snap-align:start;
    }
    @media(max-width:900px){
      .projects-h .project{
        flex:0 0 100%;
        min-width:100%;
      }
    }

    .carousel-controls{display:flex;gap:10px;justify-content:flex-end;margin-top:8px}
    .scroll-btn{background:rgba(255,255,255,.08);border:1px solid rgba(255,255,255,.14);color:var(--text);padding:8px 12px;border-radius:12px;font-weight:700;box-shadow:var(--shadow);cursor:pointer}
    .scroll-btn:hover{background:rgba(255,255,255,.12)}

    /* Unified media gallery (photos + videos) — horizontal, 3 visible */
    .media-h{display:flex;gap:22px;overflow-x:auto;padding:6px 0 10px;margin:0;scroll-snap-type:x mandatory;-webkit-overflow-scrolling:touch}
    .media-h::-webkit-scrollbar{height:10px}
    .media-h::-webkit-scrollbar-thumb{background:rgba(255,255,255,.15);border-radius:999px}
    .media-card{flex:0 0 calc((100% - 44px) / 3);min-width:calc((100% - 44px) / 3);scroll-snap-align:start;overflow:hidden;border-radius:var(--radius);background:var(--navy-2);border:1px solid rgba(255,255,255,.06);box-shadow:var(--shadow)}
    .media-cover{height:220px;background:#0d2a4e;display:flex;align-items:center;justify-content:center}
    .media-card .card-inner{padding:16px}
    .media-card video{width:100%;height:100%;display:block}
  /* Unified media gallery*/ (photos + videos) */
    .media-grid{display:grid;gap:22px}
    @media(min-width:900px){.media-grid{grid-template-columns:1fr 1fr}}
    .media-card{overflow:hidden;border-radius:var(--radius);background:var(--navy-2);border:1px solid rgba(255,255,255,.06);box-shadow:var(--shadow)}
    .media-cover{height:220px;background:#0d2a4e;display:flex;align-items:center;justify-content:center}
    .media-card .card-inner{padding:16px}
    .media-card video{width:100%;height:100%;display:block}
  
    /* Strong final overrides for blue theme and gallery fit */
    body{background:var(--navy)!important}
    .hero{background:radial-gradient(1000px 500px at 20% -10%, rgba(125,211,252,.15), transparent), radial-gradient(1000px 500px at 120% 10%, rgba(37,99,235,.12), transparent)!important}
    .hero::after{background:linear-gradient(180deg, rgba(10,35,66,.15), rgba(10,35,66,.65))!important}
    .media-h{display:flex;gap:22px;overflow-x:auto;padding:6px 0 10px;margin:0;scroll-snap-type:x mandatory;-webkit-overflow-scrolling:touch}
    .media-card{flex:0 0 calc((100% - 44px) / 3);min-width:calc((100% - 44px) / 3);scroll-snap-align:start;background:transparent!important;border:0!important;box-shadow:none!important}
    .media-card img, .media-card video{display:block;width:100%;aspect-ratio:16/9;height:auto;object-fit:cover}
    @media(max-width:980px){ .media-card{flex:0 0 calc((100% - 22px) / 2); min-width:calc((100% - 22px) / 2); } }
    @media(max-width:640px){ .media-card{flex:0 0 100%; min-width:100%; } }
    .btn.small{padding:8px 12px;border-radius:10px;font-weight:700}
  
      /* Detail modal */
    .detail-backdrop{position:fixed;inset:0;background:rgba(0,0,0,.55);backdrop-filter:blur(4px);display:none;align-items:center;justify-content:center;z-index:200}
    .detail-backdrop.show{display:flex}
    .detail-modal{position:relative;width:min(960px,94vw);max-height:88vh;display:flex;flex-direction:column;background:var(--navy-2);border:1px solid rgba(255,255,255,.12);border-radius:18px;box-shadow:0 40px 80px rgba(0,0,0,.5);overflow:hidden}
    .detail-cover img,.detail-cover video{display:block;width:100%;height:260px;object-fit:cover}
    .detail-body{padding:18px 20px 14px}
    .detail-title{margin:0 0 4px;font-size:22px}
    .detail-meta{font-size:12px;color:var(--muted);margin-bottom:10px}
    .detail-content{color:var(--text)}
    .detail-actions{display:flex;gap:10px;margin-top:10px}
    .detail-actions a{display:inline-flex;align-items:center;gap:8px;padding:10px 14px;border-radius:12px;background:#1b3f72;color:#fff;border:1px solid rgba(255,255,255,.12);text-decoration:none;font-weight:600}
    .detail-actions a:hover{background:#24518f}
    .detail-close{position:absolute;top:10px;right:10px;background:rgba(0,0,0,.45);border:1px solid rgba(255,255,255,.3);color:#fff;border-radius:999px;padding:6px 10px;font-size:13px;cursor:pointer}
    @media(max-width:640px){.detail-cover img,.detail-cover video{height:210px}}

    /* project cover images fit (not zoom) */
    .projects-h .cover img{
      object-fit:contain !important;
      background:#0d2a4e;
    }

    /* certifications horizontal scroll with ~350px cards */
    .certs-h{
      display:flex;
      gap:18px;
      overflow-x:auto;
      padding:6px 0 14px;
      scroll-snap-type:x mandatory;
      -webkit-overflow-scrolling:touch;
    }
    .certs-h .entry{
      flex:0 0 350px; /* B choice */
      scroll-snap-align:center;
    }

    /* ==========================================================
       FIX: Make long modal content scrollable (projects details)
       ========================================================== */
    .detail-body{
      overflow-y:auto;
      -webkit-overflow-scrolling:touch;
    }
    .detail-content{
      overflow-y:auto;
      max-height:calc(88vh - 340px); /* cover + header/meta + padding */
      overscroll-behavior:contain;
    }
  
    /* ==========================================================
       Skills bars (no numbers)
       ========================================================== */
    .skill{margin-bottom:14px}
    .skill span{display:block;font-size:13px;font-weight:600;color:var(--text);margin-bottom:6px}
    .bar{width:100%;height:10px;background:rgba(255,255,255,.12);border-radius:999px;overflow:hidden}
    .fill{height:100%;border-radius:999px;background:linear-gradient(90deg,#7dd3fc,#38bdf8)}
    .fill.full{width:100%}
    .fill.high{width:90%}
    .fill.strong{width:80%}
    .fill.mid{width:70%}

  </style>
</head>
<body>
  <header>
    <div class="wrap">
      <nav>
        <div class="brand"><img class="logo" src="gallery/headshot2.JPG" alt="Pavan headshot" width="40" height="40"><h1>Pavan Konam</h1></div>
        <div class="links">
          <a href="#about">About</a>
          <a href="#experience">Experience</a>
          <a href="#education">Education</a>
          <a href="#projects">Projects</a>
          <a href="#certs">Certifications</a>
          <a href="#contact">Contact</a>
          <a class="btn small" href="https://raw.githubusercontent.com/pavankonam/portfolio/main/Pavan_Resume_Oct15.pdf" download>Download Resume</a>
        </div>
      </nav>
    </div>
  </header>

  <section class="hero">
  <div class="hero-content">
    <div class="hero-inner">
      <h1 class="hero-title">Hi, I’m <span class="name-accent">Pavan Kartheek Konam</span></h1>
      <p class="hero-sub">Founder, <strong>APExpose</strong> — AI Engineer focused on LLMs, RAG, and Computer Vision.</p>
      <div class="hero-cta">
        <a class="btn" href="#projects">View Projects</a>
        <a class="btn secondary" href="#contact">Contact</a>
      </div>
    </div>
  </div>
</section>

  <section id="about">
  <div class="wrap" style="padding-top:32px">
    <h2 class="section-title" style="margin-bottom:16px">About</h2>
    <div class="cols" style="grid-template-columns: 1fr 1.2fr .9fr; align-items:stretch">
      <!-- Left: Professional photo only -->
      <div class="card" style="overflow:hidden">
        <img src="gallery/headshot.JPG" alt="Professional headshot of Pavan" style="width:100%;height:100%;object-fit:cover;object-position:top center;display:block"/>
      </div>
      <!-- Middle: concise bullets -->
      <div class="card"><div class="card-inner">
        <ul style="margin:0;padding-left:18px">
          <li>Founder of <strong>APExpose</strong>, building AI-driven media, analytics, and intelligent data products.</li>
          <li>Design and deploy <strong>production-grade RAG and LLM systems</strong> on Azure, used by real users in live workflows.</li>
          <li>Build <strong>computer vision systems</strong> for on-model imagery generation, gesture analysis, and real-time feedback.</li>
          <li>Strong experience delivering <strong>end-to-end ML pipelines</strong> from data engineering to deployment and evaluation.</li>
          <li>Teach <strong>Linear Algebra and MATLAB</strong>; mentor students through full-cycle machine learning projects.</li>
          <li>Focused on <strong>scalable, interpretable, and impact-driven</strong> AI systems.</li>
        </ul>

      </div></div>
      <!-- Right: skills bars -->
      <div class="card"><div class="card-inner">
        <h3 style="margin:0 0 14px">Skills</h3>

        <div class="skill">
          <span>Python</span>
          <div class="bar"><div class="fill full"></div></div>
        </div>

        <div class="skill">
          <span>LLMs / RAG</span>
          <div class="bar"><div class="fill high"></div></div>
        </div>

        <div class="skill">
          <span>Azure</span>
          <div class="bar"><div class="fill high"></div></div>
        </div>

        <div class="skill">
          <span>Computer Vision</span>
          <div class="bar"><div class="fill strong"></div></div>
        </div>

        <div class="skill">
          <span>TensorFlow / PyTorch</span>
          <div class="bar"><div class="fill strong"></div></div>
        </div>

        <div class="skill">
          <span>LangChain</span>
          <div class="bar"><div class="fill mid"></div></div>
        </div>

        <div class="skill" style="margin-bottom:0">
          <span>Docker / MLflow</span>
          <div class="bar"><div class="fill mid"></div></div>
        </div>
      </div></div>
    </div>
  </div>
</section>

  <section id="experience">
    <div class="wrap">
      <h2 class="section-title">Experience</h2>
      <div class="timeline">
        <div class="tl-wrap">
          <!-- APExpose Founder -->
          <article class="tl-item left expandable" data-link-url="#" data-link-text="Company site">
            <span class="connector"></span>
            <span class="dot"></span>
            <h3>Founder — APExpose</h3>
            <div class="meta">Oct 2025 – Present · Chicago</div>
            <p>Bootstrapping a media-tech startup focused on AI-powered content production workflows.</p>
            <template class="detail">
              <p><strong>What I'm building</strong></p>
              <ul>
                <li>AI-first pipeline for planning, generating, and distributing multimedia content.</li>
                <li>Core stack: Python, LLMs, vector search, lightweight CMS, analytics.</li>
                <li>Early pilots with creators and small businesses; refining product-market fit.</li>
              </ul>
            </template>
          </article>

          <!-- GTA (Fall 2025) -->
          <article class="tl-item right expandable">
            <span class="connector"></span>
            <span class="dot"></span>
            <h3>Graduate Teaching Assistant — Northwestern University</h3>
            <div class="meta">Oct 2025 – Present · Remote · Course: Machine Learning</div>
            <p>Guiding students on end-to-end ML projects and labs.</p>
            <template class="detail">
              <ul>
                <li>Supported ML pipelines using scikit-learn/TensorFlow; assisted with debugging and evaluation.
                </li>
                <li>Led office hours, labs, and grading with clear rubrics and feedback loops.
                </li>
                <li>Mentored teams on data preprocessing, model selection, cross-validation, and MLOps basics.
                </li>
              </ul>
            </template>
          </article>

          <!-- HauteCarat -->
          <article class="tl-item left expandable">
            <span class="connector"></span>
            <span class="dot"></span>
            <h3>AI Software Engineer (Intern) — HauteCarat</h3>
            <div class="meta">Jul 2025 – Sep 2025 · Chicago (On-site)</div>
            <p>Built an internal LLM/RAG platform and a CV pipeline for on-model imagery.</p>
            <template class="detail">
              <ul>
                <li>Shipped an internal multi-agent assistant, unified data with a vector DB, and exposed tools over APIs.
                </li>
                <li>Created Streamlit dashboards for analytics and operations.
                </li>
                <li>Implemented text-to-image workflows (brand-consistent on-model jewelry) and evaluation harnesses.
                </li>
                <li>Set up CI/CD with Docker and GitHub Actions; tracked runs with MLflow.
                </li>
              </ul>
            </template>
          </article>

          <!-- Professor -->
          <article class="tl-item right expandable">
            <span class="connector"></span>
            <span class="dot"></span>
            <h3>Professor (Summer Session) — McCormick School of Engineering</h3>
            <div class="meta">Jul 2025 – Aug 2025 · Evanston (On-site)</div>
            <p>Taught <em>Linear Algebra & Intro to MATLAB</em> to ~30 students.</p>
            <template class="detail">
              <ul>
                <li>Curriculum on vector spaces, linear transforms, eigen-analysis, and MATLAB implementations.</li>
                <li>Hands-on labs linking math concepts to ML and engineering use-cases.</li>
                <li>Mentored students to bridge theory and computation with applied projects.</li>
              </ul>
            </template>
          </article>

          <!-- GTA (Jan–Jul 2025) -->
          <article class="tl-item left expandable">
            <span class="connector"></span>
            <span class="dot"></span>
            <h3>Graduate Teaching Assistant — Northwestern University</h3>
            <div class="meta">Jan 2025 – Jul 2025 · Evanston (On-site)</div>
            <p>Supported instruction and grading; Python & AI topics.</p>
            <template class="detail">
              <ul>
                <li>Facilitated labs, debugging sessions, and peer learning.
                </li>
              </ul>
            </template>
          </article>

          <!-- Cognizant Programming Analyst -->
          <article class="tl-item right expandable">
            <span class="connector"></span>
            <span class="dot"></span>
            <h3>Programming Analyst — Cognizant</h3>
            <div class="meta">Jul 2022 – Aug 2024 · Hyderabad</div>
            <p>Delivered CV/NLP solutions for healthcare with production MLOps.</p>
            <template class="detail">
              <ul>
                <li>Built deep learning models for medical imaging and text using TensorFlow/PyTorch.</li>
                <li>Developed NLP chatbot and ASR; achieved ~92% accuracy in speech-to-text.
                </li>
                <li>Created scalable ML pipelines for cloud deployment; wrote technical docs and stakeholder updates.
                </li>
                <li>Applied computational biology/statistics to analyze healthcare data.
                </li>
              </ul>
            </template>
          </article>

          <!-- Cognizant Intern -->
          <article class="tl-item left expandable">
            <span class="connector"></span>
            <span class="dot"></span>
            <h3>Intern — Cognizant</h3>
            <div class="meta">Feb 2022 – Jun 2022 · Remote</div>
            <p>Computer Vision intern focusing on detection & OCR.</p>
            <template class="detail">
              <ul>
                <li>Built object-detection and text-recognition models on AWS; reached ~94% accuracy.</li>
                <li>Supported image analysis for medical diagnostics; hands-on with SQL, Azure, GCP, AWS.</li>
              </ul>
            </template>
          </article>

          <!-- Sparks Foundation -->
          <article class="tl-item right expandable">
            <span class="connector"></span>
            <span class="dot"></span>
            <h3>Project Intern — The Sparks Foundation</h3>
            <div class="meta">Jul 2021 – Sep 2022 · Hyderabad</div>
            <p>Contributed to data/AI mini-projects and mentoring.
            </p>
            <template class="detail">
              <ul>
                <li>Hands-on project work in data/ML; documented results and learnings.</li>
              </ul>
            </template>
          </article>

          <!-- Saavishkaara -->
          <article class="tl-item left expandable">
            <span class="connector"></span>
            <span class="dot"></span>
            <h3>CDO & Project Designer — Saavishkaara</h3>
            <div class="meta">May 2020 – May 2022 · Hyderabad</div>
            <p>Led product design and student projects in robotics/AI.
            </p>
            <template class="detail">
              <ul>
                <li>Directed R&D initiatives; organized training and project showcases.</li>
              </ul>
            </template>
          </article>

          <!-- 1Stop.ai -->
          <article class="tl-item right expandable">
            <span class="connector"></span>
            <span class="dot"></span>
            <h3>Artificial Intelligence Intern — 1Stop.ai</h3>
            <div class="meta">Jan 2021 – Aug 2021 · Hyderabad</div>
            <p>Worked across three AI projects with mentorship and reviews.</p>
            <template class="detail">
              <ul>
                <li>Applied CV/NLP techniques; delivered project reports and demos.</li>
              </ul>
            </template>
          </article>

          <!-- Path Creators -->
          <article class="tl-item left expandable">
            <span class="connector"></span>
            <span class="dot"></span>
            <h3>Technical Trainer — Path Creators (India)</h3>
            <div class="meta">Feb 2019 – May 2021 · On-site</div>
            <p>Trained 600+ students in robotics & IoT; 50+ hires mentored.</p>
            <template class="detail">
              <ul>
                <li>Ran hands-on workshops; built 50+ mini and 4 major projects with students.
                </li>
                <li>Skills: C++, Robotics, IoT, new-hire training.</li>
              </ul>
            </template>
          </article>
        </div>
      </div>
    </div>
  </section>

  <section id="education">
    <div class="wrap">
      <h2 class="section-title">Education</h2>
      <div class="timeline">
        <div class="tl-wrap">
          <article class="tl-item left expandable">
            <span class="connector"></span><span class="dot"></span>
            <h3>Northwestern University — MS, Artificial Intelligence</h3>
            <div class="meta">Sep 2024 – Dec 2025 · Evanston</div>
            <p>Focus on LLMs, RAG, and Computer Vision; projects in healthcare AI and production ML systems.</p>
            <template class="detail">
              <p><strong>Focus & coursework</strong> — LLMs, RAG, Computer Vision, and applied healthcare AI. Built production-style ML systems and end-to-end projects.</p>
            </template>
          </article>
          <article class="tl-item right expandable">
            <span class="connector"></span><span class="dot"></span>
            <h3>Teegala Krishna Reddy Engineering College — BTech, ECE</h3>
            <div class="meta">2018 – 2022 · Hyderabad</div>
            <p>Electronics & Communication with strong foundations in programming, signals, and applied ML.</p>
            <template class="detail">
              <p><strong>Highlights</strong> — Core ECE fundamentals, programming, and early ML projects; robotics and applied electronics.</p>
            </template>
          </article>
        </div>
      </div>
    </div>
  </section>

  <section id="projects">
    <div class="wrap">
      <h2 class="section-title">Projects</h2>
      <div class="carousel-controls">
        <button class="scroll-btn" id="proj-prev" aria-label="Previous">&#x2039;</button>
        <button class="scroll-btn" id="proj-next" aria-label="Next">&#x203A;</button>
      </div>
      <div class="projects-h">
        <!-- Intellicore -->
        <article class="card project expandable" data-link-text="(add link)" data-link-url="#">
          <div class="cover"><img src="projects/intellicore.png" alt="Intellicore cover" style="width:100%;height:220px;object-fit:cover"></div>
          <div class="card-inner">
            <h3>Intellicore — Multi-Agent RAG System</h3>
            <p class="meta">Associated with HauteCarat | Jul 2025 – Sep 2025</p>

            <p class="tagline">
              Intellicore is a production-grade multi-agent Retrieval-Augmented Generation (RAG) platform built to deliver real-time, company-wide intelligence through a conversational AI interface.
            </p>

            <div class="chips">
              <span class="chip">Multi-Agent Orchestration</span>
              <span class="chip">RAG</span>
              <span class="chip">Azure</span>
              <span class="chip">Vector Embeddings</span>
              <span class="chip">REST APIs</span>
            </div>

            <template class="detail">
              <p><strong>Overview</strong></p>
              <p>
                Intellicore is a production-grade multi-agent Retrieval-Augmented Generation (RAG) platform built to deliver real-time, company-wide intelligence through a conversational AI interface. The system unifies fragmented data across e-commerce, marketing, analytics, and customer engagement platforms, enabling non-technical stakeholders to ask complex business questions and receive accurate, grounded answers.
              </p>

              <p><strong>Technical Architecture & Analytics</strong></p>
              <ul>
                <li>Designed a multi-agent architecture with specialized agents for ingestion, normalization, retrieval, reasoning, and response synthesis, enabling modular scalability and fault isolation.</li>
                <li>Integrated Shopify, Klaviyo, Google Analytics 4, LiveChat, Facebook Ads, and Instagram Graph APIs, supporting historical backfills and incremental data syncs.</li>
                <li>Built a canonical data model (Customer, Transaction, Campaign, Event, Content) to normalize heterogeneous schemas and resolve cross-platform entity duplication.</li>
                <li>Implemented entity resolution and deduplication logic, enabling unified customer journeys across ads, sessions, purchases, and conversations.</li>
                <li>Developed RAG pipelines using semantic embeddings and filtered retrieval to ground LLM outputs strictly in live business data, minimizing hallucinations.</li>
                <li>Enabled natural-language analytics, supporting KPI queries, funnel analysis, campaign attribution, customer segmentation, and trend detection.</li>
                <li>Automated end-to-end data refresh workflows, ensuring consistent freshness and reliability across all downstream queries.</li>
              </ul>

              <p><strong>Business Impact</strong></p>
              <ul>
                <li>Replaced manual dashboard hopping with a single conversational insight layer, reducing time-to-insight for stakeholders.</li>
                <li>Improved decision accuracy and confidence by grounding AI responses in normalized, real-time operational data.</li>
                <li>Enabled proactive strategy through cross-channel analytics (marketing → behavior → conversion → revenue).</li>
                <li>Established a scalable foundation for future agent expansion, advanced forecasting, and automated recommendations.</li>
              </ul>

              <p><strong>Tech Stack</strong></p>
              <p>Python, Azure Data Lake Gen2, Azure Cognitive Search, Azure Functions, Azure OpenAI, Vector Embeddings, REST APIs, Multi-Agent Orchestration, RAG</p>
            </template>
          </div>
        </article>

        <!-- Visionary -->
        <article class="card project expandable" data-link-text="(internal)" data-link-url="#">
          <div class="cover"><img src="projects/visionary.png" alt="Visionary cover" style="width:100%;height:220px;object-fit:cover"></div>
          <div class="card-inner">
            <h3>Visionary — On-Model Jewelry Image Generation System</h3>
            <p class="meta">Associated with HauteCarat | Jul 2025 – Sep 2025</p>
            <p class="tagline">Closed-access AI platform to generate luxury, photorealistic on-model jewelry imagery at scale while preserving HauteCarat’s premium aesthetics.</p>
            <div class="chips">
              <span class="chip">Generative AI</span><span class="chip">Computer Vision</span><span class="chip">GPT-4 Vision</span><span class="chip">GPT-Image-1</span><span class="chip">Secure Deployment</span>
            </div>
            <template class="detail">
              <p><strong>Overview</strong></p>
              <p>
                Visionary is a closed-access AI-driven image generation platform designed to produce luxury, on-model jewelry photography at scale. The system analyzes HauteCarat’s existing editorial imagery and generates photorealistic, brand-consistent visuals for any jewelry product—eliminating the need for repeated photoshoots while preserving premium aesthetics.
              </p>

              <p><strong>Technical Architecture &amp; Visual Intelligence</strong></p>
              <ul>
                <li>Built a computer-vision–driven generation pipeline that analyzes reference model imagery to extract lighting conditions, skin tone, pose geometry, jewelry positioning, and editorial style.</li>
                <li>Leveraged GPT-4 Vision to semantically understand visual composition and stylistic cues from HauteCarat’s existing campaign photography.</li>
                <li>Used GPT-Image-1 to synthesize high-resolution, photorealistic on-model images aligned with the brand’s luxury identity.</li>
                <li>Engineered a flexible product-input pipeline capable of adapting any catalog jewelry image (rings, necklaces, earrings, bracelets) to the learned on-model style.</li>
                <li>Implemented prompt-engineering and visual constraints to maintain consistency across model appearance, framing, and jewelry focus.</li>
                <li>Designed the system for editorial-grade outputs, suitable for e-commerce listings, paid ads, social media campaigns, and lookbooks.</li>
                <li>Deployed as a secure, internal-only tool, with controlled access for creative and marketing stakeholders.</li>
              </ul>

              <p><strong>Business Impact</strong></p>
              <ul>
                <li>Reduced reliance on traditional photoshoots, lowering production cost and turnaround time.</li>
                <li>Enabled rapid, scalable content generation for new product launches and campaigns.</li>
                <li>Preserved brand consistency while expanding creative experimentation.</li>
                <li>Accelerated marketing workflows by allowing teams to generate on-model visuals on demand.</li>
              </ul>

              <p><strong>Tech Stack</strong></p>
              <p>Generative AI, Computer Vision, GPT-4 Vision, GPT-Image-1, Prompt Engineering, Image Synthesis, Secure Internal Deployment</p>
            </template>
          </div>
        </article>

        <!-- Amazon Review Detection -->
        <article class="card project expandable" data-link-text="GitHub" data-link-url="#">
          <div class="cover"><img src="projects/amazon-ai-detect-cover.jpg" alt="Amazon AI Detect cover" style="width:100%;height:220px;object-fit:cover"></div>
          <div class="card-inner">
            <h3>Amazon Review Human–AI Detection — NLP-powered Authenticity Classifier</h3>
            <p class="meta">Associated with Northwestern University | Apr 2025 – Jun 2025</p>
            <p class="tagline">NLP-based system to distinguish human-written vs AI-generated Amazon reviews with robust, interpretable detection.</p>
            <div class="chips">
              <span class="chip">NLP</span>
              <span class="chip">BERT</span>
              <span class="chip">Transformer Fine-Tuning</span>
              <span class="chip">Text Classification</span>
              <span class="chip">Feature Engineering</span>
            </div>
            <template class="detail">
              <p><strong>Overview</strong></p>
              <p>
                This project developed an NLP-based classification system to distinguish between human-written and AI-generated Amazon reviews, addressing the growing risk of synthetic content manipulation in online marketplaces. The system combines classical linguistic analysis with transformer-based deep learning to deliver robust and interpretable detection.
              </p>

              <p><strong>Technical Architecture &amp; Modeling</strong></p>
              <ul>
                <li>Conducted a structured review of AI text generation artifacts, stylometric signals, and adversarial writing behaviors.</li>
                <li>Curated and preprocessed a labeled Amazon review dataset containing both human-authored and AI-generated text, applying cleaning, tokenization, class balancing, and feature normalization.</li>
                <li>Built baseline classifiers (Logistic Regression, SVM) using lexical and stylometric features such as n-grams, readability scores, punctuation patterns, and sentence-level statistics.</li>
                <li>Fine-tuned BERT-based transformer models to capture subtle semantic and structural cues indicative of machine-generated text.</li>
                <li>Designed rigorous evaluation pipelines using Accuracy, Precision, Recall, F1-score, and ROC-AUC with cross-validation for generalization testing.</li>
                <li>Applied model interpretability techniques, including attention analysis and feature importance, to understand decision signals and improve trust.</li>
                <li>Compared baseline and transformer performance, iteratively tuning hyperparameters and architectures.</li>
              </ul>

              <p><strong>Impact &amp; Insights</strong></p>
              <ul>
                <li>Achieved strong classification performance (high F1 and ROC-AUC) in separating human and AI-generated reviews.</li>
                <li>Identified consistent linguistic and structural patterns leveraged by detection models.</li>
                <li>Demonstrated how NLP-based authenticity systems can help platforms preserve trust, mitigate fraud, and protect consumers.</li>
              </ul>

              <p><strong>Tech Stack</strong></p>
              <p>Python, NLP, BERT, Transformer Fine-Tuning, Text Classification, Feature Engineering, Scikit-learn, PyTorch</p>
            </template>
          </div>
        </article>
<!-- Empathetic Echoes -->
        <article class="card project expandable" data-link-text="Demo" data-link-url="#">
          <div class="cover"><img src="projects/empathetic-echoes-cover.jpg" alt="Empathetic Echoes cover" style="width:100%;height:220px;object-fit:cover"></div>
          <div class="card-inner">
            <h3>Empathetic Echoes — Emotion-Aware Psychiatric Chatbot</h3>
            <p class="meta">Associated with Northwestern University | Apr 2025 – Jun 2025</p>
            <p class="tagline">Emotion-aware conversational AI with ethical guardrails, safety escalation, and retrieval grounding for supportive mental health guidance.</p>
            <div class="chips">
              <span class="chip">Emotion Recognition</span>
              <span class="chip">Conversational AI</span>
              <span class="chip">RAG</span>
              <span class="chip">Prompt Engineering</span>
              <span class="chip">Safety Guardrails</span>
            </div>
            <template class="detail">
              <p><strong>Overview</strong></p>
              <p>
                Empathetic Echoes is an emotion-aware conversational AI designed to provide empathetic, context-sensitive mental health support while respecting ethical and safety boundaries. The system detects emotional states and adapts responses to support users with appropriate tone, intent, and grounding.
              </p>

              <p><strong>System Design &amp; Emotional Intelligence</strong></p>
              <ul>
                <li>Built an emotion detection module using fine-tuned transformer models to infer emotional states such as anxiety, sadness, frustration, and stress from user text.</li>
                <li>Designed an intent and context understanding layer mapping user inputs to therapy-relevant categories (reflection, coping strategies, grounding exercises, resource guidance).</li>
                <li>Engineered empathetic response-generation prompts, emphasizing emotional validation, supportive language, and conversational coherence.</li>
                <li>Integrated retrieval-augmented grounding, ensuring responses reference validated mental health concepts rather than free-form generation.</li>
                <li>Implemented safety and escalation logic to detect high-risk language (e.g., self-harm indicators) and trigger crisis-aware fallback messaging or human-support guidance.</li>
                <li>Evaluated system quality via human-in-the-loop testing, measuring perceived empathy, appropriateness, coherence, and helpfulness.</li>
                <li>Iteratively refined emotional calibration and prompts based on user feedback.</li>
              </ul>

              <p><strong>Impact &amp; Ethical Value</strong></p>
              <ul>
                <li>Demonstrated strong performance in simulated conversations, with high perceived empathy and contextual relevance.</li>
                <li>Showcased how emotion-aware AI systems can augment access to mental health support without replacing professional care.</li>
                <li>Emphasized ethical guardrails, safety, and responsible deployment in sensitive AI applications.</li>
              </ul>

              <p><strong>Tech Stack</strong></p>
              <p>NLP, Transformer Models, Emotion Recognition, Conversational AI, Prompt Engineering, Retrieval-Augmented Generation (RAG), Python</p>
            </template>
          </div>
        </article>
<!-- Virtual Gym Trainer -->
        <article class="card project expandable" data-link-text="GitHub" data-link-url="#">
          <div class="cover"><img src="projects/virtual-gym-cover.jpg" alt="Virtual Gym cover" style="width:100%;height:220px;object-fit:cover"></div>
          <div class="card-inner">
            <h3>Virtual Gym Trainer — Real-Time AI Fitness Coaching System</h3>
            <p class="meta">Associated with Northwestern University | Apr 2025 – Jun 2025</p>
            <p class="tagline">Computer-vision–powered fitness assistant delivering real-time posture correction, repetition counting, and exercise feedback through a webcam.</p>
            <div class="chips"><span class="chip">Computer Vision</span><span class="chip">Pose Estimation</span><span class="chip">Real-Time ML</span><span class="chip">UI Visualization</span><span class="chip">HCI</span></div>
            <template class="detail">
              
              <p><strong>Overview</strong></p>
              <p>Virtual Gym Trainer is a computer-vision–powered fitness assistant that monitors user workouts through a webcam, providing real-time posture correction, repetition counting, and exercise feedback. The system is designed to make solo training safer, more effective, and more accessible without requiring a human trainer.</p>

              <p><strong>System Architecture &amp; Real-Time Analytics</strong></p>
              <ul>
                <li>Implemented a real-time video processing pipeline to capture webcam input and extract human pose keypoints on a per-frame basis using pose estimation models.</li>
                <li>Applied pose normalization and noise filtering to handle lighting variation, camera angle differences, and diverse body proportions.</li>
                <li>Built an exercise classification module to identify movements such as squats, push-ups, and lunges based on pose dynamics.</li>
                <li>Designed state-transition logic to track start/end positions and automatically count repetitions using joint-angle thresholds.</li>
                <li>Developed a posture evaluation engine that detects form deviations and triggers corrective feedback when thresholds are exceeded.</li>
                <li>Integrated a visual feedback overlay, highlighting joints, angles, and incorrect posture in real time for intuitive correction.</li>
                <li>Validated accuracy and usability using recorded test videos and human evaluation.</li>
              </ul>

              <p><strong>Impact</strong></p>
              <ul>
                <li>Delivered accurate real-time exercise recognition and rep counting.</li>
                <li>Improved workout safety and form awareness through immediate corrective feedback.</li>
                <li>Demonstrated how vision-based systems can function as scalable virtual personal trainers.</li>
              </ul>

              <p><strong>Tech Stack</strong></p>
              <p>Computer Vision, Pose Estimation, Real-Time ML, Python, Human–Computer Interaction, UI Visualization</p>

            </template>
          </div>
        </article>

        <!-- Artistic Visualization of Dreams -->
        <article class="card project expandable" data-link-text="Paper/Repo" data-link-url="#">
          <div class="cover"><img src="projects/dreams-cover.jpg" alt="Dreams project cover" style="width:100%;height:220px;object-fit:cover"></div>
          <div class="card-inner">
            <h3>Artistic Visualization of Dreams — EEG-to-Image Deep Learning Pipeline</h3>
            <p class="meta">Associated with Northwestern University | Jan 2025 – Mar 2025</p>
            <p class="tagline">End-to-end EEG decoding pipeline that classifies dream categories from spectrograms and generates artistic visuals via a VAE.</p>
            <div class="chips"><span class="chip">EEG Processing</span><span class="chip">CNN</span><span class="chip">VAE</span><span class="chip">Signal Processing</span><span class="chip">Deep Learning</span></div>
            <template class="detail">
              
              <p><strong>Overview</strong></p>
              <p>This project explores the intersection of neuroscience and generative AI by decoding EEG signals recorded during sleep and transforming them into artistic visual representations of dream content. The system classifies dream states and generates images that reflect subconscious patterns.</p>

              <p><strong>Neural Signal Processing &amp; Generative Modeling</strong></p>
              <ul>
                <li>Compiled and unified five EEG datasets, creating a consolidated corpus of 700+ EDF files representing diverse dream experiences.</li>
                <li>Preprocessed raw EEG signals through noise filtering, frequency band extraction (Delta, Theta, Alpha, Beta, Gamma), and spectrogram generation.</li>
                <li>Designed and trained a CNN-based classifier to categorize dreams into five semantic classes:
                  <ul>
                    <li>Adventure &amp; Movement</li>
                    <li>Fear &amp; Uncertainty</li>
                    <li>People &amp; Social Interaction</li>
                    <li>Abstract &amp; Thought-based</li>
                    <li>Miscellaneous</li>
                  </ul>
                </li>
                <li>Achieved approximately 85% classification accuracy on held-out EEG samples.</li>
                <li>Integrated classification outputs with a Variational Autoencoder (VAE) to generate artistic images corresponding to predicted dream categories.</li>
                <li>Built an end-to-end pipeline: EEG decoding → dream classification → visual generation.</li>
                <li>Evaluated coherence between generated imagery and known dream narratives.</li>
              </ul>

              <p><strong>Impact</strong></p>
              <ul>
                <li>Demonstrated a novel approach to visualizing subconscious brain activity using deep learning.</li>
                <li>Showcased the feasibility of EEG-driven generative systems for neuroscience and BCI research.</li>
                <li>Bridged neural signal analysis with creative AI expression.</li>
              </ul>

              <p><strong>Tech Stack</strong></p>
              <p>EEG Processing, CNNs, VAEs, Deep Learning, Signal Processing, Python</p>

            </template>
          </div>
        </article>

        <!-- ICU Insights -->
        <article class="card project expandable" data-link-text="(case study)" data-link-url="#">
          <div class="cover"><img src="projects/icu-insights-cover.jpg" alt="ICU Insights cover" style="width:100%;height:220px;object-fit:cover"></div>
          <div class="card-inner">
            <h3>ICU Insights — Predictive Modeling for ICU Admission Risk</h3>
            <p class="meta">Associated with Northwestern University | Sep 2024 – Dec 2024</p>
            <p class="tagline">Clinical risk prediction system using MIMIC-IV data to forecast ICU admission risk and support proactive triage.</p>
            <div class="chips"><span class="chip">Healthcare Analytics</span><span class="chip">Random Forest</span><span class="chip">Neural Networks</span><span class="chip">BigQuery</span><span class="chip">SQL</span></div>
            <template class="detail">
              
              <p><strong>Overview</strong></p>
              <p>ICU Insights is a clinical risk prediction system built to forecast whether hospitalized patients are likely to require ICU admission. By identifying high-risk cases early, the model supports proactive care prioritization and resource allocation.</p>

              <p><strong>Data Engineering &amp; Predictive Modeling</strong></p>
              <ul>
                <li>Utilized the MIMIC-IV clinical database, containing de-identified records from 70,000+ ICU patients, including labs, vitals, medications, and administrative data.</li>
                <li>Engineered clinical features such as:
                  <ul>
                    <li>Ratio of abnormal to normal lab results</li>
                    <li>Frequency of lab tests</li>
                    <li>Demographics, vitals, and OMR data (BMI, blood pressure, height, weight)</li>
                  </ul>
                </li>
                <li>Developed and compared Random Forest and Feedforward Neural Network models.</li>
                <li>Built two model versions:
                  <ul>
                    <li>V1: 24 features (demographics, labs, vitals)</li>
                    <li>V2: 31 features with expanded OMR data</li>
                  </ul>
                </li>
                <li>Addressed large-scale data challenges using SQL optimization in BigQuery, chunk-based processing, and lazy loading.</li>
                <li>Handled missing values via targeted imputation strategies.</li>
              </ul>

              <p><strong>Model Performance</strong></p>
              <ul>
                <li><strong>Best Model:</strong> Random Forest</li>
                <li><strong>Test AUC-ROC:</strong> 0.973</li>
                <li><strong>Test F1 Score:</strong> 0.767</li>
                <li><strong>Recall:</strong> 0.806 | <strong>Precision:</strong> 0.731</li>
              </ul>

              <p><strong>Impact</strong></p>
              <ul>
                <li>Demonstrated strong predictive power for early ICU risk identification.</li>
                <li>Highlighted how ML-driven triage tools can improve clinical decision-making.</li>
                <li>Balanced performance, interpretability, and scalability in healthcare ML systems.</li>
              </ul>

              <p><strong>Tech Stack</strong></p>
              <p>Machine Learning, Random Forests, Neural Networks, SQL, BigQuery, Python, Healthcare Analytics</p>

            </template>
          </div>
        </article>

        <!-- Med Alert -->
        <article class="card project expandable" data-link-text="(prototype)" data-link-url="#">
          <div class="cover"><img src="projects/med-alert-cover.jpg" alt="Med Alert cover" style="width:100%;height:220px;object-fit:cover"></div>
          <div class="card-inner">
            <h3>Med Alert — Doctor Portal with Wearable Streams</h3>
            <p class="tagline">Secure patient records + smartwatch vitals; AI health summaries and recommendations.</p>
            <div class="chips"><span class="chip">Generative AI</span><span class="chip">AWS</span></div>
            <template class="detail">
              <ul>
                <li>Vitals dashboards (temp, SpO₂, HR) in tables/graphs; doctors review and message patients.</li>
              </ul>
            </template>
          </div>
        </article>

        <!-- Gesture Net -->
        <article class="card project expandable">
          <div class="cover"><img src="projects/gesture-net-cover.jpg" alt="Gesture Net cover" style="width:100%;height:220px;object-fit:cover"></div>
          <div class="card-inner">
            <h3>Gesture Net — Nonverbal Risk Signals</h3>
            <p class="tagline">Detects behavioral cues from video for early risk assessment.</p>
            <div class="chips"><span class="chip">CV</span><span class="chip">Pose</span></div>
            <template class="detail">
              <ul>
                <li>Pose/landmark extraction; temporal normalization; deep classifier for gesture categories.</li>
              </ul>
            </template>
          </div>
        </article>

        <!-- MARS -->
        <article class="card project expandable">
          <div class="cover"><img src="projects/mars-cover.jpg" alt="MARS cover" style="width:100%;height:220px;object-fit:cover"></div>
          <div class="card-inner">
            <h3>MARS — Mentorship & Academic Resource System</h3>
            <p class="tagline">Student mentorship platform with UX-driven guidance and tracking.</p>
            <div class="chips"><span class="chip">HCI</span><span class="chip">UX</span></div>
            <template class="detail">
              <ul>
                <li>User research → prototypes → usability testing; responsive web app with mentor matching.</li>
              </ul>
            </template>
          </div>
        </article>

      </div>
    </div>
  </section>

  <section id="certs">
    <div class="wrap">
      <h2 class="section-title">Certifications (selection)</h2>
      <div class="certs-h">
        <div class="entry"><h3>CITI: HIPAA Security & Privacy</h3><div class="meta">Apr 2025</div></div>
        <div class="entry"><h3>CITI: Human Research Protections (IRB)</h3><div class="meta">Apr 2025 – Apr 2028</div></div>
        <div class="entry"><h3>Coursera: Generative AI with LLMs</h3><div class="meta">Sep 2023</div></div>
        <div class="entry"><h3>IBM: Data Science Foundations</h3><div class="meta">Oct 2020</div></div>
      </div>
    </div>
  </section>

  <section id="gallery">
    <div class="wrap">
      <h2 class="section-title">Gallery</h2>
      <div class="media-h">
        <div class="media-card"><img src="gallery/newyork.jpg" alt="New York cover"/></div>
        <div class="media-card"><img src="gallery/1871.jpg" alt="1871 event"/></div>
        <div class="media-card"><img src="gallery/IMG_2936.jpg" alt="Event photo"/></div>
        <div class="media-card"><img src="gallery/IMG_4171.jpg" alt="Event photo"/></div>
        <div class="media-card"><img src="gallery/class_teaching.jpg" alt="Class teaching"/></div>
        <div class="media-card"><img src="gallery/latest_teaching.jpg" alt="Latest teaching"/></div>
        <div class="media-card"><img src="gallery/teaching.jpeg" alt="Teaching"/></div>
        <div class="media-card"><img src="gallery/teaching2.jpeg" alt="Teaching 2"/></div>
        <div class="media-card"><img src="gallery/teaching4.jpg" alt="Teaching 4"/></div>
        <div class="media-card"><img src="gallery/teaching5.jpg" alt="Teaching 5"/></div>
        <div class="media-card"><img src="gallery/teachings.jpg" alt="Teachings"/></div>
        <div class="media-card"><img src="gallery/teachnign.jpg" alt="Teaching"/></div>
        <div class="media-card"><img src="gallery/event.jpg" alt="Event"/></div>
        <div class="media-card"><img src="gallery/event_recent.jpg" alt="Recent event"/></div>
        <div class="media-card"><img src="gallery/events.JPG" alt="Events"/></div>
        <div class="media-card"><img src="gallery/graduated.jpg" alt="Graduation"/></div>
        <div class="media-card"><img src="gallery/microsoft.jpg" alt="Microsoft event"/></div>
        <div class="media-card"><img src="gallery/microsoftteam.JPG" alt="Microsoft team"/></div>
        <div class="media-card"><img src="gallery/office.jpeg" alt="Office"/></div>
        <div class="media-card"><img src="gallery/prize.jpg" alt="Prize"/></div>
        <div class="media-card"><img src="gallery/seminar-pro.jpg" alt="Seminar professional"/></div>
        <div class="media-card"><img src="gallery/seminar.jpg" alt="Seminar"/></div>
        <div class="media-card"><img src="gallery/skyline.jpg" alt="Skyline"/></div>
        <div class="media-card"><img src="gallery/working2.jpg" alt="Working"/></div>
      </div>
    </div>
  </section>

  <section id="contact">
    <div class="wrap">
      <h2 class="section-title">Contact</h2>
      <div class="card"><div class="card-inner">
        <p>Email: <a href="mailto:pavankonam2026@u.northwestern.edu">pavankonam2026@u.northwestern.edu</a> · <a href="mailto:pavankonam@gmail.com">pavankonam@gmail.com</a></p>
        <p>LinkedIn: <a href="https://www.linkedin.com/in/pavankonam/" target="_blank" rel="noopener">linkedin.com/in/pavankonam</a> · GitHub: <a href="https://github.com/pavankonam" target="_blank" rel="noopener">github.com/pavankonam</a></p>
        <p>Phone: <a href="tel:+15179402499">+1 (517) 940-2499</a></p>
        <p><a class="btn" href="https://raw.githubusercontent.com/pavankonam/portfolio/main/Pavan_Resume_Oct15.pdf" download>Download Resume</a></p>
      </div></div>
    </div>
  </section>

  <footer>
    <div class="wrap footer-grid">
      <div>© <span id="yr"></span> Pavan Konam — Built with vanilla HTML/CSS. Deployed on GitHub Pages.</div>
      <div><a href="#">Back to top ↑</a></div>
      <div>Theme: Navy Blue</div>
    </div>
  </footer>

  <!-- Detail Modal -->
  <div class="detail-backdrop" id="detail-backdrop">
    <div class="detail-modal" id="detail-modal" role="dialog" aria-modal="true" aria-labelledby="detail-title">
      <button class="detail-close" id="detail-close" aria-label="Close">✕</button>
      <div class="detail-cover" id="detail-cover"></div>
      <div class="detail-body">
        <h3 class="detail-title" id="detail-title"></h3>
        <div class="detail-meta" id="detail-meta"></div>
        <div class="detail-content card-inner" id="detail-content"></div>
        <div class="detail-actions" id="detail-actions"></div>
      </div>
    </div>
  </div>

  <script>
    // Footer year
    document.getElementById('yr').textContent = new Date().getFullYear();

    // Animate timeline entries
    const tlItems = document.querySelectorAll('.tl-item');
    const io = new IntersectionObserver((entries)=>{
      entries.forEach(e=>{ if(e.isIntersecting){ e.target.classList.add('in'); } });
    },{threshold:.35});
    tlItems.forEach(el=> io.observe(el));

    // Project carousel controls (scroll by viewport width)
    const projRow = document.querySelector('.projects-h');
    const prevBtn = document.getElementById('proj-prev');
    const nextBtn = document.getElementById('proj-next');
    function scrollByOne(dir){
      if(!projRow) return;
      const width = projRow.clientWidth;
      projRow.scrollBy({left: dir * width, behavior:'smooth'});
    }
    if(prevBtn && nextBtn){
      prevBtn.addEventListener('click', ()=>scrollByOne(-1));
      nextBtn.addEventListener('click', ()=>scrollByOne(1));
    }

    // Detail modal logic (projects + experience + education)
    const backdrop = document.getElementById('detail-backdrop');
    const modal    = document.getElementById('detail-modal');
    const dTitle   = document.getElementById('detail-title');
    const dMeta    = document.getElementById('detail-meta');
    const dCover   = document.getElementById('detail-cover');
    const dContent = document.getElementById('detail-content');
    const dActs    = document.getElementById('detail-actions');
    const dClose   = document.getElementById('detail-close');

    function openDetail(el){
      const h3 = el.querySelector('h3');
      const meta = el.querySelector('.meta');
      dTitle.textContent = h3 ? h3.textContent : 'Details';
      dMeta.textContent  = meta ? meta.textContent : '';

      // Cover: prefer data-video, then data-cover, then existing .cover img
      dCover.innerHTML = '';
      const videoSrc = el.dataset.video;
      const coverAttr = el.dataset.cover;
      if(videoSrc){
        const v = document.createElement('video');
        v.controls = true; v.playsInline = true; v.muted = false;
        const s = document.createElement('source');
        s.src = videoSrc; s.type = 'video/mp4';
        v.appendChild(s);
        dCover.appendChild(v);
      } else if(coverAttr){
        const img = document.createElement('img');
        img.src = coverAttr; img.alt = dTitle.textContent + ' cover';
        dCover.appendChild(img);
      } else {
        const fromCard = el.querySelector('.cover img');
        if(fromCard){
          const clone = fromCard.cloneNode(true);
          clone.style.width = '100%';
          clone.style.height = '260px';
          clone.style.objectFit = 'cover';
          dCover.appendChild(clone);
        }
      }

      // Content: prefer <template class="detail">
      const tpl = el.querySelector('template.detail');
      if(tpl){
        dContent.innerHTML = tpl.innerHTML;
      } else {
        const body = el.querySelector('.card-inner') || el;
        dContent.innerHTML = body.innerHTML;
      }

      // Actions: optional link button
      dActs.innerHTML = '';
      if(el.dataset.linkUrl){
        const a = document.createElement('a');
        a.href = el.dataset.linkUrl;
        a.target = '_blank';
        a.rel = 'noopener';
        a.textContent = el.dataset.linkText || 'Open link';
        dActs.appendChild(a);
      }

      backdrop.classList.add('show');
    }

    function closeDetail(){
      backdrop.classList.remove('show');
      dTitle.textContent = '';
      dMeta.textContent = '';
      dCover.innerHTML = '';
      dContent.innerHTML = '';
      dActs.innerHTML = '';
    }

    if(dClose){ dClose.addEventListener('click', closeDetail); }
    if(backdrop){
      backdrop.addEventListener('click', (e)=>{
        if(e.target === backdrop) closeDetail();
      });
    }
    window.addEventListener('keydown', (e)=>{
      if(e.key === 'Escape' && backdrop.classList.contains('show')) closeDetail();
    });

    document.querySelectorAll('.project.expandable, .tl-item.expandable').forEach(el=>{
      el.style.cursor = 'pointer';
      el.addEventListener('click', (ev)=>{
        if(ev.target.closest('a')) return; // let links behave normally
        openDetail(el);
      });
    });
  </script>
</body>
</html>
